{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'test_labels', 'train', 'train_labels']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the load method the parameter allow_pickle must \n",
    "# be set to True for unpacking the data\n",
    "npzfile = np.load('mnist.npz', allow_pickle=True)\n",
    "print(npzfile.files) # prints ['X_train', 'y_train', 'X_test', 'y_test']\n",
    "# You can access train/test data and labels as follows\n",
    "\n",
    "npzfile['train']  # outputs the X_train dataset, prints array([[0., 0., 0., ..., 0., 0., 0.], with shape (60000, 784) which contains 60000 images of 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBTrain(train_patterns, class_labels, num_features, num_classes, laplace_correction=0):\n",
    "    # Count the total number of training instances\n",
    "    num_patterns = np.shape(train_patterns)[0]\n",
    "    # Count the total number of features in each instance\n",
    "    num_attributes = np.shape(train_patterns)[1]\n",
    "    # Initialize arrays for storing log probabilities of features and classes\n",
    "    feature_log_probs = np.zeros((num_features, num_classes, num_attributes))\n",
    "    class_log_probs = np.zeros(num_classes)\n",
    "    # Loop over each training instance and feature\n",
    "    for pattern_index in range(num_patterns):\n",
    "        for attribute_index in range(num_attributes):\n",
    "            # Count occurrences of each feature for each class\n",
    "            feature_log_probs[train_patterns[pattern_index][attribute_index], class_labels[pattern_index], attribute_index] += 1\n",
    "    # Loop over each class and feature\n",
    "    for class_index in range(num_classes):\n",
    "        for attribute_index in range(num_attributes):\n",
    "            # Calculate log probabilities of each feature for each class, applying Laplace smoothing if specified\n",
    "            feature_log_probs[:, class_index, attribute_index] = np.log((feature_log_probs[:, class_index, attribute_index] + laplace_correction) / (np.sum(feature_log_probs[:, class_index, attribute_index]) + num_features * laplace_correction))\n",
    "    # Calculate log probabilities of each class\n",
    "    class_log_probs = np.log(np.bincount(class_labels) / num_patterns)\n",
    "    # Return the log probabilities of features and classes\n",
    "    return feature_log_probs, class_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBClassify(test_patterns, feature_log_probs, class_log_probs):\n",
    "    num_patterns = np.shape(test_patterns)[0]\n",
    "    num_attributes = np.shape(test_patterns)[1]\n",
    "\n",
    "    predicted_classes = np.zeros(num_patterns, dtype=int)\n",
    "\n",
    "    for pattern_index in range(num_patterns):\n",
    "        log_posterior_probs = np.zeros(class_log_probs.shape)\n",
    "        for attribute_index in range(num_attributes):\n",
    "            log_posterior_probs += feature_log_probs[test_patterns[pattern_index][attribute_index], :, attribute_index]\n",
    "        log_posterior_probs += class_log_probs\n",
    "        predicted_classes[pattern_index] = np.argmax(log_posterior_probs)\n",
    "\n",
    "    return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m laplace_val \u001b[38;5;129;01min\u001b[39;00m laplace_values:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(laplace_val)\n\u001b[1;32m---> 18\u001b[0m     feature_probs, class_probs \u001b[38;5;241m=\u001b[39m NBTrain(train_features, train_labels, feature_values_count, class_count, laplace_val)\n\u001b[0;32m     20\u001b[0m     predicted_train_labels \u001b[38;5;241m=\u001b[39m NBClassify(train_features, feature_probs, class_probs)\n\u001b[0;32m     21\u001b[0m     predicted_test_labels \u001b[38;5;241m=\u001b[39m NBClassify(test_features, feature_probs, class_probs)\n",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m, in \u001b[0;36mNBTrain\u001b[1;34m(train_patterns, class_labels, num_features, num_classes, laplace_correction)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_patterns):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attribute_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_attributes):\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# Count occurrences of each feature for each class\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m         feature_log_probs[train_patterns[pattern_index][attribute_index], class_labels[pattern_index], attribute_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Loop over each class and feature\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes):\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_features = npzfile['train']\n",
    "train_labels = npzfile['train_labels']\n",
    "\n",
    "test_features = npzfile['test']\n",
    "test_labels = npzfile['test_labels']\n",
    "laplace_values = [0, 0.001, 0.01, 0.1, 0.2, 0.4, 1, 10]\n",
    "\n",
    "results_data = []\n",
    "\n",
    "feature_values_count = np.unique(train_features).size\n",
    "class_count = np.unique(train_labels).size\n",
    "\n",
    "for laplace_val in laplace_values:\n",
    "    print(laplace_val)\n",
    "    feature_probs, class_probs = NBTrain(train_features, train_labels, feature_values_count, class_count, laplace_val)\n",
    "    \n",
    "    predicted_train_labels = NBClassify(train_features, feature_probs, class_probs)\n",
    "    predicted_test_labels = NBClassify(test_features, feature_probs, class_probs)\n",
    "    \n",
    "    training_error = 1 - accuracy_score(train_labels, predicted_train_labels)\n",
    "    testing_error = 1 - accuracy_score(test_labels, predicted_test_labels)\n",
    "    \n",
    "    results_data.append({'Error Train': training_error, 'Error Test': testing_error,'LC': laplace_val})\n",
    "    print(laplace_val)\n",
    "results_table = pd.DataFrame(results_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

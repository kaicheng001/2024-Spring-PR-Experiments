{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "#from mnist import MNIST\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as matplot\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "matplot.rcdefaults()\n",
    "from IPython.display import display, HTML\n",
    "from itertools import chain\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexamples\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtutorials\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmnist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_data\n\u001b[0;32m      2\u001b[0m mnist \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mread_data_sets(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST_data/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnist.train.images\n",
    "validation = mnist.validation.images\n",
    "test = mnist.test.images\n",
    "\n",
    "trlab = mnist.train.labels\n",
    "vallab = mnist.validation.labels\n",
    "tslab = mnist.test.labels\n",
    "\n",
    "train = np.concatenate((train, validation), axis=0)\n",
    "trlab = np.concatenate((trlab, vallab), axis=0)\n",
    "\n",
    "train = train * 255\n",
    "test = test * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes(train, train_lb, test, test_lb, smoothing):\n",
    "        n_class = np.unique(train_lb)\n",
    "        tr = train\n",
    "        te = test\n",
    "        tr_lb = train_lb\n",
    "        te_lb = test_lb\n",
    "        smoothing = smoothing\n",
    "        st = time()\n",
    "        m, s, prior, count = [], [], [], []\n",
    "        for i, val in enumerate(n_class):\n",
    "            sep = [tr_lb == val] \n",
    "            count.append(len(tr_lb[sep]))\n",
    "            prior.append(len(tr_lb[sep]) / len(tr_lb))\n",
    "            m.append(np.mean(tr[sep], axis=0))\n",
    "            s.append(np.std(tr[sep], axis=0))\n",
    "        \n",
    "        pred = []\n",
    "        likelihood = []\n",
    "        #prtab = []\n",
    "        lcs = []\n",
    "        for n in range(len(te_lb)):\n",
    "            classifier = []\n",
    "            sample = te[n] #test sample\n",
    "            ll = []\n",
    "            for i, val in enumerate(n_class):\n",
    "                m1 = m[i]\n",
    "                var = np.square(s[i]) + smoothing\n",
    "                prob = 1 / np.sqrt(2 * np.pi * var) * np.exp(-np.square(sample - m1)/(2 * var))\n",
    "                #prtab.append(prob)\n",
    "                result = np.sum(np.log(prob))\n",
    "                classifier.append(result)\n",
    "                ll.append(prob)\n",
    "\n",
    "            pred.append(np.argmax(classifier))\n",
    "            likelihood.append(ll)\n",
    "            lcs.append(classifier)\n",
    "        \n",
    "        return pred, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(confusion_matrix):\n",
    "    a = confusion_matrix\n",
    "    b = a.sum(axis=1)\n",
    "    df = []\n",
    "    for i in range(0,10):\n",
    "        temp = 1-a[i][i]/b[i]\n",
    "        df.append(temp)\n",
    "    \n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = ['% Error rate']\n",
    "    return df*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = naivebayes(train=train, train_lb=trlab, test=test, test_lb=tslab, smoothing=1000)\n",
    "nb_pred = nb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(tslab, nb_pred)\n",
    "#cm # X-axis Predicted vs Y-axis Actual Values\n",
    "matplot.subplots(figsize=(10, 6))\n",
    "sb.heatmap(cm, annot = True, fmt = 'g')\n",
    "matplot.xlabel(\"Predicted\")\n",
    "matplot.ylabel(\"Actual\")\n",
    "matplot.title(\"Confusion Matrix\")\n",
    "matplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy:\", round((sum(np.diagonal(cm)) / len(nb_pred)) * 100, 4), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
